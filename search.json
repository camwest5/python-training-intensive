[
  {
    "objectID": "Project/project.html",
    "href": "Project/project.html",
    "title": "Project landing page",
    "section": "",
    "text": "Project landing page",
    "crumbs": [
      "Project",
      "Project landing page"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html",
    "href": "WIPs/2 - Data processing.html",
    "title": "Data Processing",
    "section": "",
    "text": "In this second workshop we will cover - Examining / exploring data - Filtering rows and columns - Basic descriptive statistics - Adding new columns - Group bys and summary tables\nThis hands-on course – directed at intermediate users – looks at using the pandas module to transform and visualise tabular data.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#introducing-pandas",
    "href": "WIPs/2 - Data processing.html#introducing-pandas",
    "title": "Data Processing",
    "section": "Introducing pandas",
    "text": "Introducing pandas\nPandas is a Python module that introduces dataframes to Python. It gives us the tools we need to clean and transform data with Python.\nTo be able to use the functions included in pandas, we have to first import it:\nimport pandas as pd\npd is the usual nickname for the pandas module.\n\nIf you get an error, like No module named 'pandas', you’ll need to install it first, using either conda install pandas or pip install pandas, depending on your Python installation.\n\n\nThe DataFrame object\nPandas is built upon one key feature: the DataFrame class. In Python we have different built-in types, like int for integers and string for characters. Pandas introduces a new type, DataFrame, which stores data like a spreadsheet.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#importing-data",
    "href": "WIPs/2 - Data processing.html#importing-data",
    "title": "Data Processing",
    "section": "Importing data",
    "text": "Importing data\nOur data is a CO2 emission dataset from Our World in Data: https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv\nIt is available under a CC-BY licence, an open licence that requires that any sharing or derivative of it needs to attribute the original source and authors.\nMore information about the dataset is included online, and the codebook, which is important to understand what exactly are the variables in the dataset, is also available online.\nWe can import it directly with pandas, with:\ndf_raw = pd.read_csv('https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv')\nUsing the type() function confirms what type of variable the data is stored as:\ntype(df_raw)\nThis dataset is a fairly big one. We can investigate its size thanks to the shape attribute attached to all pandas dataframes:\ndf_raw.shape\nThe dataset contains dozens of columns. What are their names?\ndf_raw.columns\nLet’s subset our data to focus on a handful of variables.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#subsetting-data",
    "href": "WIPs/2 - Data processing.html#subsetting-data",
    "title": "Data Processing",
    "section": "Subsetting data",
    "text": "Subsetting data\nWe want to focus on only a few columns, especially since a lot of the data can be inferred from those.\nWe want to keep 8 columns:\n\nThe iso_code, which is very useful for matching several datasets without having to worry about variations in country names\ncountry\nyear\npopulation\ngdp\nThe three main greenhouse gases, which according to the codebook are all in million tonnes of CO2-equivalent:\n\nco2\nmethane\nnitrous_oxide\n\n\nTo only keep these columns, we can index the dataframe with a list of names:\nkeep = ['iso_code', 'country', 'year', 'population', 'gdp', 'co2', 'methane', 'nitrous_oxide']\ndf = df_raw[keep]\nThe other issue with the data is that it starts in the 18th century, but we might want to ignore early patchy data:\ndf = df[df.year &gt;= 1900]\nWe can check that it has worked:\nmin(df.year)\nIt looks like the dataset is also consistently missing values for nitrous oxide and methane for the last few years.\n\nChallenge 1: remove recent patchy years\nHow can you remove the patchy years after 2018? Design an operation that is similar to removing the pre-1900 data.\nCan you add a second command to check it has done the right thing?\nSolution:\ndf = df[df.year &lt; 2019]\nmax(df.year)\nYou could also run both subsets at the same time by separating them with brackets and using &\ndf2 = df[(df.year &gt;= 1900) & (df.year &lt;= 2018)]",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#exploring-data",
    "href": "WIPs/2 - Data processing.html#exploring-data",
    "title": "Data Processing",
    "section": "Exploring data",
    "text": "Exploring data\nTo check what kind of data each column is stored as, we can use the dtypes attribute:\ndf.dtypes\nThe describe() method is useful for descriptive statistics about our numerical columns:\ndf.describe()\nHowever, it will only show the two first ones and two last ones. We can focus on a specific column instead, for example one that was hidden previously:\ndf.co2.describe()\nOr a categorical column:\ndf.country.describe()\n\nFor a categorical column, the information shown is different: for example, how many unique values there are, and what the most common value is.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#more-cleaning-up",
    "href": "WIPs/2 - Data processing.html#more-cleaning-up",
    "title": "Data Processing",
    "section": "More cleaning up",
    "text": "More cleaning up\nNotice that the maximum co2 value (given above in df.co2.describe()) is 36826.508. Which country does this maximum value belong to? Let’s investigate this by subsetting the data:\ndf[df.co2 == df.co2.max()]\nWe use a condition that will be checked against each row, and only the row that contains the maximum value will be returned.\nThe maximum co2 value is associated with the whole world. Many datasets have aggregate regions on top of single countries, which is something to keep in mind!\nHere, we see that this entry has no ISO code (given as nan, not a number). We can find out how many rows do not have an ISO code at all by using Spyder’s data explorer or by using two methods stringed together:\ndf.iso_code.isna().sum()\nisna() returns the boolean values True or False depending on if the data is missing, and the sum() method can give a total of Trues (because it converts True to 1, and False to 0).\nSimilarly, we can average boolean values to find the fraction of missing data:\ndf.iso_code.isna().mean()\nAlternatively, pandas dataframes have a count() method to give a count of non-NA values for each column:\ndf.count()\nWe can see that quite a few rows have missing ISO codes, which for the most part indicates an aggregate region. So how do we remove all that superfluous data?\nAgain, by using a logical test. But first, check what will be removed:\ndf[df.iso_code.isna()].country.unique()\nNow to remove aggregate regions:\ndf = df[df.iso_code.notna()]\nWe can now check what actual countries are left in the dataset, with the unique() method:\ndf.country.unique()",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#adding-columns",
    "href": "WIPs/2 - Data processing.html#adding-columns",
    "title": "Data Processing",
    "section": "Adding columns",
    "text": "Adding columns\nNow that we have a clean dataset, we can expand it by calculating new interesting variables.\nFor example, we can first sum the three greenhouse gases (as they use the same unit), and then calculate how much CO2-equivalent is emitted per person. We can also add GDP per capita to the dataset.\nFor the total greenhouse gas emissions in CO2e:\ndf['co2e'] = df[['co2', 'methane', 'nitrous_oxide']].sum(axis=1)\nThe operation is done row-wise: we use axis=1 to specify that we apply the function in the column axis.\nYou can confirm by looking at the data that the NA values are skipped when calculating the sum. The help page for this method mentions the skipna argument, which is set to True by default:\ndf.sum?\nskipna : bool, default True\n    Exclude NA/null values when computing the result.\nAnd then, for the CO2e per capita and the GDP per capita:\ndf['co2e_pc'] = df.co2e / df.population\ndf['gdp_pc'] = df.gdp / df.population\nWe now have three extra columns in our dataset.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#merging-tables",
    "href": "WIPs/2 - Data processing.html#merging-tables",
    "title": "Data Processing",
    "section": "Merging tables",
    "text": "Merging tables\nIt is common to want to merge two datasets from two different sources. To do that, you will need common data to match rows on.\nWe want to add the countries’ Social Progress Index to our dataset.\n\nYou can find out more about the SPI on their website: https://www.socialprogress.org/\n\nThe SPI dataset also has a three-letter code for the countries, which we can match to our existing iso_code column. We have an SPI for several different years, so we should match that column as well:\n# read the data\nspi = pd.read_csv('https://gist.githubusercontent.com/stragu/57b0a0750678bada09625d429a0f806b/raw/a18a454d7d225bd24074399a7ab79a4189e53501/spi.csv')\n# merge on two columns\ndf_all = pd.merge(df, spi,\n                  left_on=['iso_code', 'year'],\n                  right_on=['country_code', 'year'])\nWe specified the two data frames, and which columns we wanted to merge on. However, we end up losing a lot of data. Looking at the documentation for the merge() function, we can see that there are many ways to merge tables, depending on what we want to keep:\npd.merge?\nThe how argument defines which kind of merge we want to do. Because we want to keep all of the data from df, we want to do a “left merge”:\ndf_all = pd.merge(df, spi,\n                  how='left',\n                  left_on=['iso_code', 'year'],\n                  right_on=['country_code', 'year'])\nWe can now “drop” the useless country_code column:\ndf_all.pop('country_code')\n\nNotice that the pop method is an “in-place” method: you don’t need to reassign the variable.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#summaries",
    "href": "WIPs/2 - Data processing.html#summaries",
    "title": "Data Processing",
    "section": "Summaries",
    "text": "Summaries\nThe aggregate() method, which has a shorter alias agg(), allows creating summaries by applying a function to a column. In combination with the groupby() method, we can create summary tables. For example, to find the average SPI for each country, and then sort the values in descending order:\ndf_all.groupby('country').spi.agg('mean').sort_values(ascending=False)\nIf you want to export that summary table and use it outside Spyder, you can first save it as a variable, and then write it to a CSV file:\nspi_sum = df_all.groupby('country').spi.agg('mean').sort_values(ascending=False)\n# write to file\nspi_sum.to_csv('spi_summary.csv')\n\nThe CSV file should be found in your project directory, as it became the default working directory when we created the project.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#visualising-data",
    "href": "WIPs/2 - Data processing.html#visualising-data",
    "title": "Data Processing",
    "section": "Visualising data",
    "text": "Visualising data\npandas integrates visualisation tools, thanks to the plot() method and its many arguments.\nFor example, to visualise the relationship between CO2e per capita and SPI:\ndf_all.plot(x='co2e_pc', y='spi')\nThe default kind of plot is a line plot, so let’s change that to a scatterplot:\ndf_all.plot(x='co2e_pc', y='spi', kind='scatter')\nFocusing on the latest year will guarantee that there only is one point per country:\ndf_all[df_all.year == 2016].plot(x='co2e_pc',\n                                 y='spi',\n                                 kind='scatter')\nTo visualise a third variable, GDP per capita, let’s map it to the colour of the points, thanks to the c argument:\ndf_all[df_all.year == 2016].plot(x='co2e_pc',\n                                 y='spi',\n                                 c='gdp_pc',\n                                 colormap='viridis',\n                                 kind='scatter')\nWe can change the labels too:\ndf_all[df_all.year == 2016].plot(x='co2e_pc',\n                                 y='spi',\n                                 c='gdp_pc',\n                                 colormap='viridis',\n                                 kind='scatter',\n                                 xlabel='GHG per capita (MT CO2e/yr)',\n                                 ylabel='Social Progress Index')\nIf the x labels don’t show, try this workaround: https://github.com/pandas-dev/pandas/issues/36064#issuecomment-1011175535\n\nChallenge 2: GHG timeline\nHow would you visualise global GHG emissions over the years, with one line per type of GHG?\nWe can subset the columns that matter to us, create a summary, and plot it:\nsub = df_all[['year', 'co2', 'methane', 'nitrous_oxide']]\nsub.groupby('year').agg('sum').plot(ylabel='MT CO2e')\nRemember that the default kind of plot in this function is 'line', which works for this visualisation. And as we fed it a series variable with several columns, it automatically assigned a different colour to each one.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#saving-your-work",
    "href": "WIPs/2 - Data processing.html#saving-your-work",
    "title": "Data Processing",
    "section": "Saving your work",
    "text": "Saving your work\nYour project can be reopened from the “Projects” menu in Spyder.\nBy default, your variables are not saved, which is another reason why working with a script is important: you can execute the whole script in one go to get everything back. You can however save your variables as a .spydata file if you want to (for example, if it takes a lot of time to process your data).",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#resources",
    "href": "WIPs/2 - Data processing.html#resources",
    "title": "Data Processing",
    "section": "Resources",
    "text": "Resources\n\nOfficial pandas documentation\n\nGetting started\n10 Minutes to pandas\nUser guide\n\nMore visualisation modules:\n\nAltair\nBokeh\nVega\nMatplotlib\n\nAbout our datasets:\n\nOur World in Data\nSocial Progress Index\n\nOur compilation of useful Python links",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "Workshops/Workshops.html",
    "href": "Workshops/Workshops.html",
    "title": "Workshops landing page",
    "section": "",
    "text": "Workshops landing page",
    "crumbs": [
      "Workshops",
      "Workshops landing page"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Python Training Intensive",
    "section": "",
    "text": "Welcome to the Python Training Intensive!",
    "crumbs": [
      "Python Training Intensive"
    ]
  },
  {
    "objectID": "setup.html#setting-up",
    "href": "setup.html#setting-up",
    "title": "Python Training Intensive",
    "section": "Setting Up",
    "text": "Setting Up\nWe are going to use Spyder for writing and running Python. This is a friendly interactive development environment (IDE) aimed at researchers. However, you are more than welcome to use your own!\nPlease set up Python and your IDE in advance.\nIf you don’t have Python or an IDE, we recommend installing Spyder, which comes with Python.",
    "crumbs": [
      "Python Training Intensive"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html",
    "href": "WIPs/1 - Fundamentals.html",
    "title": "The Fundamentals",
    "section": "",
    "text": "In this first workshop we will cover",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#introducing-python-and-spyder",
    "href": "WIPs/1 - Fundamentals.html#introducing-python-and-spyder",
    "title": "The Fundamentals",
    "section": "Introducing Python and Spyder",
    "text": "Introducing Python and Spyder\nPython is a programming language that can be used to build programs (i.e. a “general programming language”), but it can also be used to analyse data by importing a number of useful modules.\nWe are using Spyder to interact with Python more comfortably. If you have used RStudio to interact with R before, you should feel right at home: Spyder is a program designed for doing data science with Python.\nPython can be used interactively in a console, or we can build scripts and programs with it, making the most out of Spyder’s code editor.\nWe will start by using the console to work interactively. This is our direct line to the computer, and is the simplest way to run code. Don’t worry about any unfamiliar language, fonts or colours - we can ignore most of it for now - all you need to know is that\n\nIn [1]: ... is code that we’ve sent to the computer, and\nOut[1]: ... is its response.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#first-glance-arithmetic",
    "href": "WIPs/1 - Fundamentals.html#first-glance-arithmetic",
    "title": "The Fundamentals",
    "section": "First glance: arithmetic",
    "text": "First glance: arithmetic\nTo start with, we can use Python like a calculator. Type the following commands in the console, and press Enter to execute them:\n1 + 1\n2 * 3\n4 / 10\n5 ** 2\nAfter running each command, you should see the result as an output.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#variables",
    "href": "WIPs/1 - Fundamentals.html#variables",
    "title": "The Fundamentals",
    "section": "Variables",
    "text": "Variables\nLike language, Python has nouns and verbs. We call the nouns variables: they are the ‘things’ we manipulate with our code.\nEssentially, a variable is a named container. We access it by its name, and we get its value.\nTo create a variable, you need to choose a name and a value with name = value. For example\nexample_int = 42\nWhenever you use the variable’s name, Python will now access its value:\nexample_int\nWe can use the variables in place of the values\nexample_float = 5.678\nproduct = example_int * example_float\nproduct\n\nSpyder helps us with extra panels and features apart from the Console. To see what variables you have created, look at the “Variable explorer” tab in the top right.\n\n\nTypes\nVariables have different types. So far, we’ve just looked at storing numbers, of which there are three types:\n\nint - integers store whole numbers, e.g. 1, 5, 1000, -3.\nfloat - floating point numbers store decimals and scientific notation, e.g. 1.5, -8.97, 4e-6.\ncomplex - complex numbers express the imaginary unit with j, e.g. z = 1+2j is \\(z = 1+2i\\).\n\nLet’s look at some other types\n\nBooleans\nEven simpler than integers is the boolean type. These are either 1 or 0 (True or False), representing a single binary unit (bit). Don’t be fooled by the words, these work like numbers: True + True gives 2.\nexample_bool = True\n\nIn Python, the boolean values True and False must begin with a capital letter.\n\n\n\nStrings\nLet’s look at variable types which aren’t (necessarily) numbers. Sequences are variables which store multiple pieces of data. For example, strings store a sequence of characters and are created with quotation marks 'blah blah blah' or \"blah blah blah\":\nexample_string = 'This is an example of a string!'\n\n\nLists\nWe can also create lists, which will store several variables (not necessarily of the same type). We need to use square brackets for that:\nexample_numbers = [38, 3, 54, 17, 7]\nexample_diverse = [3, 'Hi!', 9.0]\nLists are very flexible as they can contain any number of items, and any type of data. You can even nest lists inside a list, which makes for a very flexible data type.\nOperations on sequences are a bit different to numbers. We can still use + and *, but they will concatenate (append) and duplicate, rather than perform arithmetic.\nexample_string + ' How are you?'\nexample_numbers + example_diverse\n3 * example_numbers\nHowever, depending on the variable, some operations won’t work:\nsentence + favNumber\nThere are other data types like tuples, dictionaries and sets, but we won’t look at those in this session. Here’s a summary of the ones we’ve covered:\n\n\n\n\n\n\n\n\n\n\nCategory\nType\nShort name\nExample\nGenerator\n\n\n\n\nNumeric\nInteger\nint\n3\nint()\n\n\nNumeric\nFloating Point Number\nfloat\n4.2\nfloat()\n\n\nNumeric\nBoolean\nbool\nTrue\nbool()\n\n\nSequence\nString\nstr\n'A sentence '\n\" \" or ' ' or str()\n\n\nSequence\nList\nlist\n['apple', 'banana', 'cherry']\n[ ] or list()\n\n\n\nThe generator commands are new. We use these to manually change the variable type. For example,\nint(True)\nyields 1, converting a boolean into an integer. These commands are functions, as opposed to variables - we’ll look at functions a bit later.\n\n\n\nIndexing\nWe can access part of a sequence by indexing. Sequences are ordered, starting at 0, so the first element has index 0, the second index 1, the third 2 and so on. For example, see what these commands return:\nexample_string[0]\nexample_string[6]\nexample_numbers[4]\nIf you want more than one element in a sequence, you can slice. Simple slices specify a range to slice, from the first index to the last, but not including the last. For example:\nmyList[0:4]\nThat command returns elements from position 0 up to - but not including! - position 4.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#scripts",
    "href": "WIPs/1 - Fundamentals.html#scripts",
    "title": "The Fundamentals",
    "section": "Scripts",
    "text": "Scripts\nSo far, we’ve been working in the console, our direct line to the computer. However, it is often more convenient to use a script. These are simple text files which store code and run when we choose. They are useful to\n\nwrite code more comfortably,\nstore clearly defined steps in chronological order,\nshare a process with peers easily, and\nmake your work reproducible\n\nLet’s create a folder system to store our script in by creating a project.\n\nPress Projects &gt; New project... and name your project, perhaps “python_training”.\nCreate a new script with ctrl+N, File &gt; New file... or the new file button.\n\nYou should now see a script on the left panel in Spyder, looking something like this:\nTry typing a line of code in your new script, such as\nexample_message = \"This is an example message\"\nexample_message\nPress F9 to run each line, or ctrl+enter for the whole script. You should see something like the following appear in the console (depending on how you ran it):\nWe’ll work out of a script for the rest of the session. Don’t forget to save your script by pressing ctrl+S or the save button. )",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#functions",
    "href": "WIPs/1 - Fundamentals.html#functions",
    "title": "The Fundamentals",
    "section": "Functions",
    "text": "Functions\nFunctions are little programs that do specific jobs. These are the verbs of Python, because they do things to and with our variables. Here are a few examples of built-in functions:\nlen(myList)\nmin(myList)\nmax(myList)\nsum(myList)\nround(otherNumber)\nFunctions always have parentheses () after their name, and they can take one or several arguments, or none at all, depending on what they can do, and how the user wants to use them.\nHere, we use two arguments to modify the default behaviour of the round() function:\nround(otherNumber, 2)\n\nNotice how Spyder gives you hints about the available arguments after typing the function name?\n\n\nOperators\nOperators are a special type of function in Python with which you’re already familiar. The most important is =, which assigns values to variables. Here is a summary of some important operators, although there are many others:\n\nGeneral\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\n\n\n\n\n=\nAssignment\nAssigns values to variables\na = 7\n\n\n#\nComment\nExcludes any following text from being run\n# This text will be ignored by Python\n\n\n\n\n\nMathematical\n\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\nExample output\n\n\n\n\n+\nAddition\nAdds or concatenates values, depending on variable types\n7 + 3 or \"a\" + \"b\"\n10 or 'ab'\n\n\n-\nSubtraction\nSubtracts numerical values\n8 - 3\n5\n\n\n*\nMultiplication\nMultiplies values, depending on variable types\n7 * 2 or \"a\" * 3\n14 or 'aaa'\n\n\n/\nDivision\nDivides numerical vlues\n3 / 4\n0.75\n\n\n**\nExponentiation\nRaises a numerical value to a power\n7 ** 2\n49\n\n\n%\nRemainder\nTakes the remainder of numerical values\n13 % 7\n6\n\n\n\n\n\nComparison\n\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\nExample output\n\n\n\n\n==\nEqual to\nChecks whether two variables are the same and outputs a boolean\n1 == 1\nTrue\n\n\n!=\nNot equal to\nChecks whether two variables are different\n'1' != 1\nTrue\n\n\n&gt;\nGreater than\nChecks whether one variable is greater than the other\n1 &gt; 1\nFalse\n\n\n&gt;=\nGreater than or equal to\nChecks whether greater than (&gt;) or equal to (==) are true\n1 &gt;= 1\nTrue\n\n\n&lt;\nLess than\nChecks whether one variable is less than the other\n0 &lt; 1\nTrue\n\n\n&lt;=\nLess than or equal to\nChecks whether less than (&lt;) or equal to (==) are true\n0 &lt;= 1\nTrue",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#finding-help",
    "href": "WIPs/1 - Fundamentals.html#finding-help",
    "title": "The Fundamentals",
    "section": "Finding help",
    "text": "Finding help\nTo find help about a function, you can use the help() function, or a ? after a function name:\nhelp(max)\nprint?\nIn Spyder, you can use the Ctrl + I keyboard shortcut to open the help in a separate pane.\nFor a comprehensive manual, go to the official online documentation. For questions and answers, typing the right question in a search engine will usually lead you to something helpful. If you can’t find an answer, StackOverflow is a great Q&A community.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#modules",
    "href": "WIPs/1 - Fundamentals.html#modules",
    "title": "The Fundamentals",
    "section": "Modules",
    "text": "Modules\nPython, on its own, requires a lot of manual programming for advanced tasks. What makes it versatile is the capacity to use other people’s code with modules.\nTo bring in advanced variables and functions that other’s have made, we need to import the module. For example\npi\nreturns an error, because it’s undefined. But the math module contains a variable called pi:\nimport math\nmath.pi\n\nTo access objects from within a module, we use a full stop: module.object_inside.\n\n\nNumPy for arrays\nArrays are a data type introduced by numpy, a module with many functions useful for numerical computing.\nFor example, you can convert the list we created before to then do mathematical operations on each one of its elements:\nimport numpy as np\nexample_array = np.array(example_numbers)\nexample_array * 2\n\n\nPandas for dataframes\npandas introduces dataframes, which are often used to store two-dimensional datasets with different kinds of variables in each column. If your data is stored as a spreadsheet, you probably want to import it with a pandas function.\nHere is an example of creating a pandas dataframe from scratch, populating it by hand:\nimport pandas as pd\n\n# Create initial dataframe\ndf = pd.DataFrame(columns=['Name', 'Age'])\n\n# Populate with data\ndf.loc[1] = 'Josephine', 70\ndf.loc[2] = 'Dilsah', 38\n\ndf\n\nYou can double-click on a dataframe in the Variable explorer to explore it in a separate window.\n\n\n\nMatplotlib for visualisation\nmatplotlib is a large collection of data visualisation functions, and pyplot is a submodule of matplotlib that contains essentials.\nimport matplotlib.pyplot as plt\nplt.plot(example_array)\nThis shows a plot in the Plots tab of Spyder.\n\nIn a Python shell, you might have to use the plt.show() command to show the plot.\n\nThe default look is a line plot that joins all the points, but we can style a plot with only a few characters:\n# blue circles\nplt.plot(example_array, 'bo')\n\n# green squares, dashed line:\nplt.plot(example_array, 'gs--')\nExtra arguments can be used to style further:\n# red, diamonds, solid line; change width of line and size of diamonds:\nplt.plot(example_array, 'rd-', linewidth=3, markersize=10)\nTo find out about the styling shorthand and all other arguments, look at the documentation:\nplt.plot?\n\n\nInstalling modules that aren’t built in\nThe math module is built-in - the module came when I installed Python, and the numpy, pandas and matplotlib come with conda installations. Most other modules live online, so we need to download and install them first.\nInstalling modules depends on whether you have a conda environment or not. To check, run\nconda\n\n\n\n\n\n\n\nMessage\nconda Environment?\n\n\n\n\nconda is a tool for managing and deployi... or something similar\nYes\n\n\nNameError: name 'conda' is not defined\nNo\n\n\n\n\nIf you have a conda environment\nYou can install packages with\nconda install package_name\n\nYou likely have a conda environment if you installed Anaconda or you installed Spyder 6 (Since Oct 2024)\n\n\n\nIf you do not have a conda environment\nYou can install packages with\npip install package_name\n\nYou likely have a pip environment if you installed Python manually and/or are not using Spyder\n\n\n\n\nPlotly Express for interactive visualisations\nOne module that isn’t built-in is plotly, which we can use for interactive visualisations.\nimport plotly.io as pio\nimport plotly.express as px\n\n# Set renderer\npio.renderers.default='browser'\n\n# Create bar plot\npx.bar(df, x = \"Name\", y = \"Age\")",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#saving-your-work",
    "href": "WIPs/1 - Fundamentals.html#saving-your-work",
    "title": "The Fundamentals",
    "section": "Saving your work",
    "text": "Saving your work\nPress “Save” or Ctrl + S to save your script.\nYour project can be reopened from the “Projects” menu in Spyder.\nBy default, your variables are not saved, which is another reason why working with a script is important: you can execute the whole script in one go to get everything back. You can however save your variables as a .spydata file if you want to (for example, if it takes a lot of time to process your data).",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#summary",
    "href": "WIPs/1 - Fundamentals.html#summary",
    "title": "The Fundamentals",
    "section": "Summary",
    "text": "Summary\nThis morning we looked at a lot of Python features, so don’t worry if they haven’t all sunk in. Programming is best learned through practice, so keep at it! Here’s a rundown of the concepts we covered\n\n\n\n\n\n\n\nConcept\nDesctiption\n\n\n\n\nThe console vs scripts\nThe console is our window into the computer, this is where we send code directly to the computer. Scripts are files which we can write, edit, store and run code, that’s where you’ll write most of your Python.\n\n\nVariables\nVariables are the nouns of programming, this is where we store information, the objects and things of our coding. They come in different types like integers, strings and lists.\n\n\nIndexing\nIn order to access elements of a sequence variable, like a list, we need to index, e.g. example_numbers[2]. Python counts from 0.\n\n\nFunctions\nFunctions are the verbs of programming, they perform actions on our variables. Call the function by name and put inputs inside parentheses, e.g. round(2.5)\n\n\nHelp\nRunning help( ... ) will reveal the help documentation about a function or type.\n\n\nPackages\nWe can bring external code into our environment with import .... This is how we use packages, an essential for Python. Don’t forget to install the package first!",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/3 - Visualisation.html",
    "href": "WIPs/3 - Visualisation.html",
    "title": "Visualisation",
    "section": "",
    "text": "Visualisation\nIn this second workshop we will cover - Simple visualisations with matplotlib - Interactive visualisations with plotly",
    "crumbs": [
      "WIPs",
      "Visualisation"
    ]
  }
]