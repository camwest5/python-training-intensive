[
  {
    "objectID": "Project/project.html",
    "href": "Project/project.html",
    "title": "Project landing page",
    "section": "",
    "text": "Project landing page",
    "crumbs": [
      "Project",
      "Project landing page"
    ]
  },
  {
    "objectID": "WIPs/5 - Statistics.html",
    "href": "WIPs/5 - Statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "This session is aimed as an overview of how to perform some statistical modelling with Python. It is a Python workshop, not a statistics workshop - if you’d like to better understand the statistical models, or need help deciding what’s best for you, please consult a statistics resource or contact a statistician.\nIn this session, we’ll cover\nWe’ll use three new modules: - numpy - scipy.stats - statsmodels\nWe’ll be working from our “Players2024” dataset again. To bring it in and clean it up,",
    "crumbs": [
      "WIPs",
      "Statistics"
    ]
  },
  {
    "objectID": "WIPs/5 - Statistics.html#descriptive-statistics",
    "href": "WIPs/5 - Statistics.html#descriptive-statistics",
    "title": "Statistics",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nWe’ll start with sample size. All dataframes have most descriptive statistics functions available right off the bat which we access via the . operator.\nTo calculate the number of non-empty observations in a column, say the numeric variable df[\"height_cm\"], we use the .count() method\ndf[\"height_cm\"].count()\n\nMeasures of central tendancy\nWe can compute measures of central tendancy similarly. The average value is given by\ndf[\"height_cm\"].mean()\nthe median by\ndf[\"height_cm\"].median()\nand the mode by\ndf[\"height_cm\"].mode()\n\n.mode() returns a dataframe with the most frequent values as there can be multiple.\n\n\n\nMeasures of variance\nWe can also compute measures of variance. The minimum and maximum are as expected\ndf[\"height_cm\"].min()\ndf[\"height_cm\"].max()\nThe range is the difference\ndf[\"height_cm\"].min() - df[\"height_cm\"].max()\nQuantiles are given by .quantile(...) with the fraction inside. The inter-quartile range (IQR) is the difference between 25% and 75%.\nq1 = df[\"height_cm\"].quantile(0.25)\nq3 = df[\"height_cm\"].quantile(0.75)\nIQR = q3 - q1\nA column’s standard deviation and variance are given by\ndf[\"height_cm\"].std()\ndf[\"height_cm\"].var()\nAnd the standard error of the mean (SEM) with\ndf[\"height_cm\"].sem()\nYou can calculate the skewness and kurtosis (variation of tails) of a sample with\ndf[\"height_cm\"].skew()\ndf[\"height_cm\"].kurt()\nAll together, you can see a nice statistical summary with\ndf[\"height_cm\"].describe()\n\n\nMeasures of correlation\nIf you’ve got two numeric variables, you might want to examine covariance and correlation. These indicate how strongly the variables are linearly related. We’ll need to use the df[\"Age\"] variable as well.\nThe covariance between “height_cm” and “Age” is\ndf[\"height_cm\"].cov(df[\"Age\"])\n\nThe .cov() function compares the column it’s attached to (here df[\"height_cm\"]) with the column you input (here df[\"Age\"]). This means we could swap the columns without issue:\ndf[\"Age\"].cov(df[\"height_cm\"])\n\nSimilarly, we can find the Pearson correlation coefficient between two columns.\ndf[\"height_cm\"].corr(df[\"Age\"])\nYou can also specify “kendall” or “spearman” for their respective correlation coefficients\ndf[\"height_cm\"].corr(df[\"Age\"], method = \"kendall\")\ndf[\"height_cm\"].corr(df[\"Age\"], method = \"spearman\")\n\n\nReminder about groupbys\nBefore we move to inferential statistics, it’s worth reiterating the power of groupbys discussed in the second workshop.\nTo group by a specific variable, like “positions”, we use\ngb = df.groupby(\"positions\")\nBy applying our statistics to the gb object, we’ll apply them to every variable for each position. Note that we should specify numeric_only = True, because these statistics won’t work for non-numeric variables\ngb.mean(numeric_only = True)",
    "crumbs": [
      "WIPs",
      "Statistics"
    ]
  },
  {
    "objectID": "WIPs/5 - Statistics.html#inferential-statistics",
    "href": "WIPs/5 - Statistics.html#inferential-statistics",
    "title": "Statistics",
    "section": "Inferential Statistics",
    "text": "Inferential Statistics\nInferential statistics requires using the module scipy.stats, which we’ll bring in with\nimport scipy.stats as stats\n\nSimple linear regressions\nLeast-squares regression for two sets of measurements can be performed with the function stats.linregress():\nstats.linregress(x = min_heights[\"Age\"], y = df[\"height_cm\"])\nIf we store this as a variable, we can access the different values with the . operator. For example, the p-value is\nlm = stats.linregress(x = df[\"Age\"], y = df[\"height_cm\"])\nlm.pvalue\n\nPlotting it\nNaturally, you’d want to plot this. We’ll need to use the overlaying techniques from the visualisation session. Let’s import seaborn and matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nStart by making a scatterplot of the data,\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\")\nThen, you’ll need to plot the regression as a line. For reference,\n\\[ y = \\text{slope}\\times x + \\text{intercept}\\]\nSo\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\")\n\nx_lm = df[\"Age\"]\ny_lm = lm.slope*x_lm + lm.intercept\nsns.lineplot(x = x_lm, y = y_lm, color = \"r\")\n\n\n\n\\(t\\)-tests\nWe can also perform \\(t\\)-tests with the scipy.stats module. Typically, this is performed to examine the statistical signficance of a difference between two samples’ means. Let’s examine whether that earlier groupby result for is accurate for heights, specifically, are goalkeepers taller than non-goalkeepers?\nLet’s start by separating the goalkeepers from the non-goalkeepers in two variables\ngoalkeepers = df[df[\"positions\"] == \"Goalkeeper\"]\nnon_goalkeepers = df[df[\"positions\"] != \"Goalkeeper\"]\nThe \\(t\\)-test for the means of two independent samples is given by\nstats.ttest_ind(goalkeepers[\"height_cm\"], non_goalkeepers[\"height_cm\"])\nYielding a p-value of \\(8\\times 10^{-247}\\approx 0\\), indicating that the null-hypothesis (heights are the same) is extremely unlikely.\n\n\nANOVAs\nWhat about the means of the other three? We could use an ANOVA to examine them. We use the stats.f_oneway() function for this. However, this requires us to send a list of samples in for each group, so we should separate the three positions.\ndefender = df[df[\"positions\"] == \"Defender\"].height_cm\nmidfield = df[df[\"positions\"] == \"Midfield\"].height_cm\nattack = df[df[\"positions\"] == \"Attack\"].height_cm\nWe can then perform the ANOVA on this list of samples\nstats.f_oneway(defender, midfield, attack)\nWith \\(p = 3\\times10^{-84}\\), it looks like their positions are not all independent of height.\n\n\n\\(\\chi^2\\) tests\n\\(χ^2\\) tests are useful for examining the relationship of categorical variables by comparing the frequencies of each. Often, you’d use this if you can make a contingency table.\nWe only have one useful categorical variable here, “positions” (the others have too many unique values), so we’ll need to create another. Let’s see if there’s a relationship between players’ positions and names with the letter “a”.\nMake a binary column for players with the letter “a” in their names. To do this, we need to apply a string method to all the columns in the dataframe as follows\ndf[\"a_in_name\"] = df[\"name\"].str.contains(\"a\")\nLet’s cross tabulate positions with this new column\na_vs_pos = pd.crosstab(df[\"positions\"],df[\"a_in_name\"])\nprint(a_vs_pos)\nThe \\(χ^2\\) test’s job is to examine whether players’ positions depend on the presence of “a” in their name. To evaluate it we need to send the contingency table in:\nstats.chi2_contingency(a_vs_pos)\n\n\nMore complex modelling\nIf you need to do more advanced statistics, particularly if you need more regressions, you’ll likely need to turn to a different package: statsmodels. It is particularly useful for statistical modelling.\nWe’ll go through three examples\n\nSimple linear regressions (like before)\nMultiple linear regressions\nLogistic regressions\n\nWhat’s nice about statsmodels is that it gives an R-like interface and summaries.\nTo start with, let’s import the tools. We’ll use the formula interface, which offers us an R-like way of creating models.\nimport statsmodels.formula.api as smf\n\nSimple linear regressions revisited\nLet’s perform the same linear regression as before, looking at the “Age” and “height variables”. Our thinking is that players’ heights dictate how long they can play, so we’ll make \\(x = \\text{height\\_cm}\\) and \\(y = \\text{Age}\\).\nThe first step is to make the set up the variables. We’ll use the function smf.ols() for ordinary least squares. It takes in two imputs:\n\nThe formula string, in the form y ~ X1 + X2 ...\nThe data\n\nWe create the model and compute the fit\nmod = smf.ols(\"Age ~ height_cm\", df)\nres = mod.fit()\nDone! Let’s take a look at the results\nres.summary()\nThat’s a lot nicer than with scipy. We can also make a plot by getting the model’s \\(y\\) values with res.fittedvalues\nsns.relplot(data = df, x = \"height_cm\", y = \"Age\")\nsns.lineplot(x = df[\"Age\"], y = res.fittedvalues, color = \"black\")\n\n\nGeneralised linear models\nThe statsmodels module has lots of advanced statistical models available. We’ll take a look at one more: Generalised Linear Models. The distributions they include are\n\nBinomial\nPoisson\nNegative Binomial\nGaussian (Normal)\nGamma\nInverse Gaussian\nTweedie\n\nWe’ll use the binomial option to create logistic regressions.\nLogistic regressions examine the distribution of binary data. For us, we can compare the heights of goalkeepers vs non-goalkeepers again. Let’s make a new column which is 1 for goalkeepers and 0 for non-goalkeepers:\ndf[\"gk\"] = (df[\"positions\"] == \"Goalkeeper\")*1\n\nWe have to multiply by 1 to turn True \\(\\rightarrow\\) 1 and False \\(\\rightarrow\\) 0\n\nNow, we can model this column with height. Specifically,\n\\[ \\text{gk} \\sim \\text{height\\_cm}\\]\nStart by making the model with the function smf.glm(). We need to specify the family of distributions; they all live in sm.families:\nmod = smf.glm(\"gk ~ height_cm\", data = df, family = sm.families.Binomial())\nNext, evaluate the results\nres = mod.fit()\nLet’s have a look at the summary:\nres.summary()\nFinally, we can plot the result like before\nsns.relplot(data = df, x = \"height_cm\", y = \"gk\")\nsns.lineplot(x = df[\"height_cm\"], y = res.fittedvalues, color = \"black\")",
    "crumbs": [
      "WIPs",
      "Statistics"
    ]
  },
  {
    "objectID": "WIPs/3 - Visualisation.html",
    "href": "WIPs/3 - Visualisation.html",
    "title": "Visualisation",
    "section": "",
    "text": "In this third workshop we will cover\nSee analysis.py for seaborn stuff.",
    "crumbs": [
      "WIPs",
      "Visualisation"
    ]
  },
  {
    "objectID": "WIPs/3 - Visualisation.html#setting-up",
    "href": "WIPs/3 - Visualisation.html#setting-up",
    "title": "Visualisation",
    "section": "Setting up",
    "text": "Setting up\nWith the data manipulation tools from pandas, we can now visualise our data. For this workshop we’ll be working from the “Players2024.csv” dataset, which we should bring in with pandas:\nimport pandas as pd\ndf = pd.read_csv(\"data/Players2024.csv\")\nTake a quick peak at the dataset to remind yourself\nprint(df)",
    "crumbs": [
      "WIPs",
      "Visualisation"
    ]
  },
  {
    "objectID": "WIPs/3 - Visualisation.html#seaborn-for-simple-visualisations",
    "href": "WIPs/3 - Visualisation.html#seaborn-for-simple-visualisations",
    "title": "Visualisation",
    "section": "Seaborn for simple visualisations",
    "text": "Seaborn for simple visualisations\nTo begin our visualisations, we’ll use the package seaborn, which allows you to quickly whip up decent graphs.\nimport seaborn as sns\n\nIt’s called “seaborn” as a reference to fictional character Sam Seaborn, whose initials are “sns”.\n\nSeaborn has three plotting functions\nsns.catplot(...) # for categorical plotting, e.g. bar plots, box plots etc.\nsns.relplot(...) # for relational plotting, e.g. line plots, scatter plots\nsns.displot(...) # for distributions, e.g. histograms\nWe’ll begin with the first.\n\nCategorical plots\nCategorical plots are produced with seaborn’s sns.catplot() function. There are two key pieces of information to pass:\n\nThe data\nThe variables\n\nLet’s see if there’s a relationship between the players’ heights and positions, by placing their positions on the \\(x\\) axis and heights on the \\(y\\).\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\")\nOur first graph! This is called a swarm plot; it’s like a scatter plot for categorical variables.\nIt’s already revealed two things to us about the data:\n\nThere are some incorrect heights - nobody is shorter than 25cm!\nSomeone’s position is “missing”\n\nLet’s get rid of these with the data analysis techniques from last session\n# Remove missing position\ndf = df[df[\"positions\"] != \"Missing\"]\n\n# Ensure reasonable heights\ndf = df[df[\"height_cm\"] &gt; 100]\nRun the plot again, it’s more reasonable now\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\")\n\nBar plots\nSwarm plots are interesting but not standard. You can change the plot type with the kind parameter\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"bar\")\n\nMany aspects of your plot can be adjusted by sending in additional parameters and is where seaborn excels.\n\nIt seems like goalkeepers are taller, but not by much. Let’s look at the standard deviation for each position by changing the estimator = parameter (default is mean)\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"bar\", estimator = \"std\")\nClearly there’s a lot less variation in goalkeepers - they’re all tall.\n\n\nBox plots\nLet’s make box plots instead. It’s the same procedure, just change to kind = \"box\" and remove estimator =\nsns.catplot(data = df, x = \"positions\", y = \"height_cm\", kind = \"box\")\nJust as we predicted.\n\n\n\nDistributions\n\nHistograms\nLet’s move to the “Age” parameter now. We can look at the distribution of ages with\nsns.displot(data = df, x = \"Age\")\nLooks a bit funny with those gaps - let’s change the number of bins with bins = 28\nsns.displot(data = df, x = \"Age\", bins = 28)\nNow, what if you wanted to look at the distribution for different variables? We can make a separate distribution for each position with the col = \"position\" argument, specifying a new column for each position\nsns.displot(data = df, x = \"Age\", bins = 28, col = \"positions\")\n\n\nKernel density estimates\nFinally, you don’t have to do histograms. You could also do a Kernel Density Estimate, with kind = \"kde\" (let’s remove bins = and col =)\nsns.displot(data = df, x = \"Age\", kind = \"kde\")\nIf you want a separate line for each position, we should indicate that each position needs a different colour/hue with hue = \"position\"\nsns.displot(data = df, x = \"Age\", hue = \"position\", kind = \"kde\")\n\n\n\nRelational plots\nIt seems like players peak in their mid-twenties, but goalkeepers stay for longer. Let’s see if there’s a relationship between players’ age and height\n\nScatter plots\nWe’ll start with a scatter plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\")\nNot much of a trend there, although the bottom-right looks a bit emptier than the rest (could it be that short old players are the first to retire?).\nWe can use hue = to have a look at positions again\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", hue = \"positions\")\nYup, goalkeepers are tall, and everyone else is a jumble.\n\n\nLine plots\nLet’s do a line plot of the average height per age.\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", kind = \"line\")\nSeems pretty flat, except the ends are a bit weird because there’s not much data. Let’s eliminate everything before 17 and after 38 and plot it\n# Create smaller dataframe\ncondition = (df[\"Age\"] &gt; 17) & (df[\"Age\"] &lt; 38)\ninner_ages = df[condition]\n\n# Line plot\nsns.relplot(data = inner_ages, x = \"Age\", y = \"height_cm\", kind = \"line\")\nLooks a bit shaky but that’s just because it’s zoomed in - notice that we go from 182cm to 184cm. We’ll fix this when we look at matplotlib in the next section.\n\n\nCombining the two\nWe can combine our scatter and line plots together.\n\nMake the first plot as normal\nFor all additional (overlaying) plots, use an axes-level plot instead of sns.relplot() etc. These just draw the points/bars/lines, and are normally behind-the-scenes. There’s one for every plot type, and look like\n\nsns.lineplot()\nsns.scatterplot()\nsns.boxplot()\nsns.histplot()\netc.\n\n\nFor example,\n# Figure level plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", hue = \"positions\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"Age\", y = \"height_cm\")\n\nYou can’t include kind = inside an axes level plot\n\nLet’s swap the colour variable from the scatter plot to the line plot\n# Figure level plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"Age\", y = \"height_cm\", hue = \"positions\")\nFinally, let’s make the scatter dots smaller with s = 10 and grey with color = \"grey\".\n# Figure level plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"Age\", y = \"height_cm\", hue = \"positions\")",
    "crumbs": [
      "WIPs",
      "Visualisation"
    ]
  },
  {
    "objectID": "WIPs/3 - Visualisation.html#going-deeper-with-matplotlib",
    "href": "WIPs/3 - Visualisation.html#going-deeper-with-matplotlib",
    "title": "Visualisation",
    "section": "Going deeper with matplotlib",
    "text": "Going deeper with matplotlib\nSeaborn is great for simple and initial visualisations, but when you need to make adjustments it gets tricky. At its core, seaborn is just a simple way of using matplotlib, an extensive and popular plotting package. It was created as a way of doing MATLAB visualisations with Python, so if you’re coming from there, things will feel familiar.\nPros\n\nCustomisable. You can tweak almost every parameter of the visualisations\nFast. It can handle large data\nPopular. Lots of people use it, and knowing it will help you collaborate\n\nCons - a bit programmy\n\nSteep-ish learning curve. Creating basic plots can be easy, but its set up with enough complexity that it takes a bit of work to figure out what’s going on.\nCumbersome. You can tweak almost everything, but this means that it can take some effort to tweak anything.\n\nWe’re barely going to touch the matplotlib surface, but we’ll look at some essentials.\nTo begin with, we want to bring in matplotlib as follows\nimport matplotlib.pyplot as plt\n\nSaving plots\nBefore we move to adjusting the plot, let’s just look at how you save it. While you can do this with seaborn, the matplotlib way is also very simple.\nAs a first step, you should make a new folder. Navigate using your file explorer to the project and create a new folder called “plots”.\nNext, save the current plot with plt.savefig(\"place_location_here\"), and we have to do this at the same time that we make the plot. So run all this code at once:\n# Figure level plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"Age\", y = \"height_cm\", hue = \"positions\")\n\nplt.savefig(\"plots/first_saved_plot.png\")\n\n\nMaking modifications\n\nTitles\nNotice that the \\(y\\) axis has an ugly label? That’s because seaborn is just drawing from your dataframe.\nWe can change axis labels with\nplt.ylabel(\"Height (cm)\")\nand similarly you could change plt.xlabel(...).\n\nMake sure you run the above line at the same time as your plotting function. You can either * Highlight all the code and press F9 * Make a cell with #%% and press ctrl + enter\n\nWe can also change the legend title to “Position”\nplt.legend(title = \"Position\")\nAnd its location with loc = \"lower left\"\nplt.legend(title = \"Position\", loc = \"lower left\")\nAnd give the whole plot a title with\nplt.title(\"Players' heights vs ages\")\nAll of these together, with the plot, look like\n# Figure level plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"Age\", y = \"height_cm\", hue = \"positions\")\n\n# Titles\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"Position\")\nplt.title(\"Players' heights vs ages\")\n\n\n\nAnnotations\nYou might want to annotate your plot with text and arrows. Text is simple with the plt.text() function; we just need to specify its coordinates and the contents.\nplt.text(38.5, 181, \"Not enough\\ndata for mean\")\n\nThe characters \\n mean ‘new line’\n\nWe could annotate with arrows too. This is more complex,\nplt.annotate(text = \"No short\\nolder players\", xy = [37,165], xytext = [40,172],\n             arrowprops = dict(width = 1, headwidth = 10, headlength = 10, \n                          facecolor = \"black\"))\n\nI’ve split this over multiple lines, but its still one function - check the brackets\n\nAll together, our plot has become\n# Figure level plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"Age\", y = \"height_cm\", hue = \"positions\")\n\n# Titles\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"Position\", loc = \"lower left\")\nplt.title(\"Players' heights vs ages\")\n\n# Annotations\nplt.text(38.5, 181, \"Not enough\\ndata for mean\")\nplt.annotate(\"No short\\nolder players\", [37,165], [40,172], \n             arrowprops = dict(width = 1,headwidth = 10,headlength = 10, \n                               facecolor = \"black\"))\n\n\nAxis limits\nThe last feature we’ll look at is editing axis limits. Let’s try to make more room in the bottom left for the legend with the functions plt.xlim() and plt.ylim()\n# Figure level plot\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", s = 10, color = \"grey\")\n\n# Axes level plot (drop the kind = )\nsns.lineplot(data = inner_ages, x = \"Age\", y = \"height_cm\", hue = \"positions\")\n\n# Titles\nplt.ylabel(\"Height (cm)\")\nplt.legend(title = \"Position\", loc = \"lower left\")\nplt.title(\"Players' heights vs ages\")\n\n# Annotations\nplt.text(38.5, 181, \"Not enough\\ndata for mean\")\nplt.annotate(\"No short\\nolder players\", [37,165], [40,172], \n             arrowprops = dict(width = 1,headwidth = 10,headlength = 10, \n                               facecolor = \"black\"))\n\n# Axis limits\nplt.xlim([10,45])\nplt.ylim([150,210])\nI’m not sure that looks any better, but you get the idea!",
    "crumbs": [
      "WIPs",
      "Visualisation"
    ]
  },
  {
    "objectID": "WIPs/3 - Visualisation.html#interactivity-with-plotly",
    "href": "WIPs/3 - Visualisation.html#interactivity-with-plotly",
    "title": "Visualisation",
    "section": "Interactivity with plotly",
    "text": "Interactivity with plotly\nFor the last part of this section, we’re going to briefly look at making interactive plots with plotly.\nWe bring in the tools with\nimport plotly.express as px\n\nYou’ll probably need to install it first - use either\nconda install plotly\nOR\npip install plotly\ndepending on your installation.\n\nPlotly works by creating a visualisation like we’ve been doing, and then loading it into something dynamic, like a web browser. Spyder does not support interactive plots. This means we need to change the default settings with\nimport plotly.io as pio\npio.renderers.default = \"browser\"\nNow, plots should all load in your default browser.\n\nThe basics\nWe make plotly graphs very similarly to seaborn. Let’s take our first plot from above,\nsns.relplot(data = df, x = \"Age\", y = \"height_cm\", s = 10, color = \"grey\")\nand turn it into a plotly one.\n\nWe need to use px.scatter instead of sns.relplot\nWe need to use data_frame = instead of data =\nLet’s remove the s = and color = for now\nSave the plot as a variable\n\npx.scatter(data_frame = df, x = \"Age\", y = \"height_cm\")\nNotice how you can hover over the points now? It’s interactive!\n\n\nIntroducing more info and neatening up\nLike seaborn’s “hue”, we can use color = to introduce a third variable\npx.scatter(data_frame = df, x = \"Age\", y = \"height_cm\", color = \"position\")\nAnd like seaborn’s “col”, we can facet with facet_col =\npx.scatter(data_frame = df, x = \"Age\", y = \"height_cm\", color = \"position\",\n           facet_col = \"positions\")\nPersonally, I think these are too squished. We can specify the maximum number of columns with facet_col_wrap =\npx.scatter(data_frame = df, x = \"Age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2)\nFinally, let’s adjust the information in the hover. We can give each point a name with hover_name = - how about their actual names?\npx.scatter(data_frame = df, x = \"Age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\")\nAnd let’s also include their nationalities\npx.scatter(data_frame = df, x = \"Age\", y = \"height_cm\", color = \"positions\",\n           facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\",\n           hover_data = \"nationality\")\n\n\nSaving interactive plots\nSince these are interactive, we can’t save them as normal. The easiest option is to save them as HTML files - like websites - which we can open from our browsers.\nFirst, save the plot into a variable\nfig = px.scatter(data_frame = df, x = \"Age\", y = \"height_cm\", color = \"positions\",\n                 facet_col = \"positions\", facet_col_wrap = 2, hover_name = \"name\",\n                 hover_data = \"nationality\")\nThen, write it to HTML\nfig.write_html(\"plot.html\")",
    "crumbs": [
      "WIPs",
      "Visualisation"
    ]
  },
  {
    "objectID": "WIPs/3 - Visualisation.html#conclusion",
    "href": "WIPs/3 - Visualisation.html#conclusion",
    "title": "Visualisation",
    "section": "Conclusion",
    "text": "Conclusion",
    "crumbs": [
      "WIPs",
      "Visualisation"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html",
    "href": "WIPs/1 - Fundamentals.html",
    "title": "The Fundamentals",
    "section": "",
    "text": "In this first workshop we will cover",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#introducing-python-and-spyder",
    "href": "WIPs/1 - Fundamentals.html#introducing-python-and-spyder",
    "title": "The Fundamentals",
    "section": "Introducing Python and Spyder",
    "text": "Introducing Python and Spyder\nPython is a programming language that can be used to build programs (i.e. a “general programming language”), but it can also be used to analyse data by importing a number of useful modules.\nWe are using Spyder to interact with Python more comfortably. If you have used RStudio to interact with R before, you should feel right at home: Spyder is a program designed for doing data science with Python.\nPython can be used interactively in a console, or we can build scripts and programs with it, making the most out of Spyder’s code editor.\nWe will start by using the console to work interactively. This is our direct line to the computer, and is the simplest way to run code. Don’t worry about any unfamiliar language, fonts or colours - we can ignore most of it for now - all you need to know is that\n\nIn [1]: ... is code that we’ve sent to the computer, and\nOut[1]: ... is its response.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#first-glance-arithmetic",
    "href": "WIPs/1 - Fundamentals.html#first-glance-arithmetic",
    "title": "The Fundamentals",
    "section": "First glance: arithmetic",
    "text": "First glance: arithmetic\nTo start with, we can use Python like a calculator. Type the following commands in the console, and press Enter to execute them:\n1 + 1\n2 * 3\n4 / 10\n5 ** 2\nAfter running each command, you should see the result as an output.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#variables",
    "href": "WIPs/1 - Fundamentals.html#variables",
    "title": "The Fundamentals",
    "section": "Variables",
    "text": "Variables\nLike language, Python has nouns and verbs. We call the nouns variables: they are the ‘things’ we manipulate with our code.\nEssentially, a variable is a named container. We access it by its name, and we get its value.\nTo create a variable, you need to choose a name and a value with name = value. For example\nexample_int = 42\nWhenever you use the variable’s name, Python will now access its value:\nexample_int\nWe can use the variables in place of the values\nexample_float = 5.678\nproduct = example_int * example_float\nproduct\n\nSpyder helps us with extra panels and features apart from the Console. To see what variables you have created, look at the “Variable explorer” tab in the top right.\n\n\nTypes\nVariables have different types. So far, we’ve just looked at storing numbers, of which there are three types:\n\nint - integers store whole numbers, e.g. 1, 5, 1000, -3.\nfloat - floating point numbers store decimals and scientific notation, e.g. 1.5, -8.97, 4e-6.\ncomplex - complex numbers express the imaginary unit with j, e.g. z = 1+2j is \\(z = 1+2i\\).\n\nLet’s look at some other types\n\nBooleans\nEven simpler than integers is the boolean type. These are either 1 or 0 (True or False), representing a single binary unit (bit). Don’t be fooled by the words, these work like numbers: True + True gives 2.\nexample_bool = True\n\nIn Python, the boolean values True and False must begin with a capital letter.\n\n\n\nStrings\nLet’s look at variable types which aren’t (necessarily) numbers. Sequences are variables which store multiple pieces of data. For example, strings store a sequence of characters and are created with quotation marks 'blah blah blah' or \"blah blah blah\":\nexample_string = 'This is an example of a string!'\n\n\nLists\nWe can also create lists, which will store several variables (not necessarily of the same type). We need to use square brackets for that:\nexample_numbers = [38, 3, 54, 17, 7]\nexample_diverse = [3, 'Hi!', 9.0]\nLists are very flexible as they can contain any number of items, and any type of data. You can even nest lists inside a list, which makes for a very flexible data type.\nOperations on sequences are a bit different to numbers. We can still use + and *, but they will concatenate (append) and duplicate, rather than perform arithmetic.\nexample_string + ' How are you?'\nexample_numbers + example_diverse\n3 * example_numbers\nHowever, depending on the variable, some operations won’t work:\nsentence + favNumber\nThere are other data types like tuples, dictionaries and sets, but we won’t look at those in this session. Here’s a summary of the ones we’ve covered:\n\n\n\n\n\n\n\n\n\n\nCategory\nType\nShort name\nExample\nGenerator\n\n\n\n\nNumeric\nInteger\nint\n3\nint()\n\n\nNumeric\nFloating Point Number\nfloat\n4.2\nfloat()\n\n\nNumeric\nBoolean\nbool\nTrue\nbool()\n\n\nSequence\nString\nstr\n'A sentence '\n\" \" or ' ' or str()\n\n\nSequence\nList\nlist\n['apple', 'banana', 'cherry']\n[ ] or list()\n\n\n\nThe generator commands are new. We use these to manually change the variable type. For example,\nint(True)\nyields 1, converting a boolean into an integer. These commands are functions, as opposed to variables - we’ll look at functions a bit later.\n\n\n\nIndexing\nWe can access part of a sequence by indexing. Sequences are ordered, starting at 0, so the first element has index 0, the second index 1, the third 2 and so on. For example, see what these commands return:\nexample_string[0]\nexample_string[6]\nexample_numbers[4]\nIf you want more than one element in a sequence, you can slice. Simple slices specify a range to slice, from the first index to the last, but not including the last. For example:\nmyList[0:4]\nThat command returns elements from position 0 up to - but not including! - position 4.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#scripts",
    "href": "WIPs/1 - Fundamentals.html#scripts",
    "title": "The Fundamentals",
    "section": "Scripts",
    "text": "Scripts\nSo far, we’ve been working in the console, our direct line to the computer. However, it is often more convenient to use a script. These are simple text files which store code and run when we choose. They are useful to\n\nwrite code more comfortably,\nstore clearly defined steps in chronological order,\nshare a process with peers easily, and\nmake your work reproducible\n\nLet’s create a folder system to store our script in by creating a project.\n\nPress Projects &gt; New project... and name your project, perhaps “python_training”.\nCreate a new script with ctrl+N, File &gt; New file... or the new file button.\n\nYou should now see a script on the left panel in Spyder, looking something like this:\nTry typing a line of code in your new script, such as\nexample_message = \"This is an example message\"\nexample_message\nPress F9 to run each line, or ctrl+enter for the whole script. You should see something like the following appear in the console (depending on how you ran it):\nWe’ll work out of a script for the rest of the session. Don’t forget to save your script by pressing ctrl+S or the save button. )",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#functions",
    "href": "WIPs/1 - Fundamentals.html#functions",
    "title": "The Fundamentals",
    "section": "Functions",
    "text": "Functions\nFunctions are little programs that do specific jobs. These are the verbs of Python, because they do things to and with our variables. Here are a few examples of built-in functions:\nlen(myList)\nmin(myList)\nmax(myList)\nsum(myList)\nround(otherNumber)\nFunctions always have parentheses () after their name, and they can take one or several arguments, or none at all, depending on what they can do, and how the user wants to use them.\nHere, we use two arguments to modify the default behaviour of the round() function:\nround(otherNumber, 2)\n\nNotice how Spyder gives you hints about the available arguments after typing the function name?\n\n\nOperators\nOperators are a special type of function in Python with which you’re already familiar. The most important is =, which assigns values to variables. Here is a summary of some important operators, although there are many others:\n\nGeneral\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\n\n\n\n\n=\nAssignment\nAssigns values to variables\na = 7\n\n\n#\nComment\nExcludes any following text from being run\n# This text will be ignored by Python\n\n\n\n\n\nMathematical\n\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\nExample output\n\n\n\n\n+\nAddition\nAdds or concatenates values, depending on variable types\n7 + 3 or \"a\" + \"b\"\n10 or 'ab'\n\n\n-\nSubtraction\nSubtracts numerical values\n8 - 3\n5\n\n\n*\nMultiplication\nMultiplies values, depending on variable types\n7 * 2 or \"a\" * 3\n14 or 'aaa'\n\n\n/\nDivision\nDivides numerical vlues\n3 / 4\n0.75\n\n\n**\nExponentiation\nRaises a numerical value to a power\n7 ** 2\n49\n\n\n%\nRemainder\nTakes the remainder of numerical values\n13 % 7\n6\n\n\n\n\n\nComparison\n\n\n\n\n\n\n\n\n\n\nOperator\nFunction\nDescription\nExample command\nExample output\n\n\n\n\n==\nEqual to\nChecks whether two variables are the same and outputs a boolean\n1 == 1\nTrue\n\n\n!=\nNot equal to\nChecks whether two variables are different\n'1' != 1\nTrue\n\n\n&gt;\nGreater than\nChecks whether one variable is greater than the other\n1 &gt; 1\nFalse\n\n\n&gt;=\nGreater than or equal to\nChecks whether greater than (&gt;) or equal to (==) are true\n1 &gt;= 1\nTrue\n\n\n&lt;\nLess than\nChecks whether one variable is less than the other\n0 &lt; 1\nTrue\n\n\n&lt;=\nLess than or equal to\nChecks whether less than (&lt;) or equal to (==) are true\n0 &lt;= 1\nTrue",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#finding-help",
    "href": "WIPs/1 - Fundamentals.html#finding-help",
    "title": "The Fundamentals",
    "section": "Finding help",
    "text": "Finding help\nTo find help about a function, you can use the help() function, or a ? after a function name:\nhelp(max)\nprint?\nIn Spyder, you can use the Ctrl + I keyboard shortcut to open the help in a separate pane.\nFor a comprehensive manual, go to the official online documentation. For questions and answers, typing the right question in a search engine will usually lead you to something helpful. If you can’t find an answer, StackOverflow is a great Q&A community.",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#modules",
    "href": "WIPs/1 - Fundamentals.html#modules",
    "title": "The Fundamentals",
    "section": "Modules",
    "text": "Modules\nPython, on its own, requires a lot of manual programming for advanced tasks. What makes it versatile is the capacity to use other people’s code with modules.\nTo bring in advanced variables and functions that other’s have made, we need to import the module. For example\npi\nreturns an error, because it’s undefined. But the math module contains a variable called pi:\nimport math\nmath.pi\n\nTo access objects from within a module, we use a full stop: module.object_inside.\n\n\nNumPy for arrays\nArrays are a data type introduced by numpy, a module with many functions useful for numerical computing.\nFor example, you can convert the list we created before to then do mathematical operations on each one of its elements:\nimport numpy as np\nexample_array = np.array(example_numbers)\nexample_array * 2\n\n\nPandas for dataframes\npandas introduces dataframes, which are often used to store two-dimensional datasets with different kinds of variables in each column. If your data is stored as a spreadsheet, you probably want to import it with a pandas function.\nHere is an example of creating a pandas dataframe from scratch, populating it by hand:\nimport pandas as pd\n\n# Create initial dataframe\ndf = pd.DataFrame(columns=['Name', 'Age'])\n\n# Populate with data\ndf.loc[1] = 'Josephine', 70\ndf.loc[2] = 'Dilsah', 38\n\ndf\n\nYou can double-click on a dataframe in the Variable explorer to explore it in a separate window.\n\n\n\nMatplotlib for visualisation\nmatplotlib is a large collection of data visualisation functions, and pyplot is a submodule of matplotlib that contains essentials.\nimport matplotlib.pyplot as plt\nplt.plot(example_array)\nThis shows a plot in the Plots tab of Spyder.\n\nIn a Python shell, you might have to use the plt.show() command to show the plot.\n\nThe default look is a line plot that joins all the points, but we can style a plot with only a few characters:\n# blue circles\nplt.plot(example_array, 'bo')\n\n# green squares, dashed line:\nplt.plot(example_array, 'gs--')\nExtra arguments can be used to style further:\n# red, diamonds, solid line; change width of line and size of diamonds:\nplt.plot(example_array, 'rd-', linewidth=3, markersize=10)\nTo find out about the styling shorthand and all other arguments, look at the documentation:\nplt.plot?\n\n\nInstalling modules that aren’t built in\nThe math module is built-in - the module came when I installed Python, and the numpy, pandas and matplotlib come with conda installations. Most other modules live online, so we need to download and install them first.\nInstalling modules depends on whether you have a conda environment or not. To check, run\nconda\n\n\n\n\n\n\n\nMessage\nconda Environment?\n\n\n\n\nconda is a tool for managing and deployi... or something similar\nYes\n\n\nNameError: name 'conda' is not defined\nNo\n\n\n\n\nIf you have a conda environment\nYou can install packages with\nconda install package_name\n\nYou likely have a conda environment if you installed Anaconda or you installed Spyder 6 (Since Oct 2024)\n\n\n\nIf you do not have a conda environment\nYou can install packages with\npip install package_name\n\nYou likely have a pip environment if you installed Python manually and/or are not using Spyder\n\n\n\n\nPlotly Express for interactive visualisations\nOne module that isn’t built-in is plotly, which we can use for interactive visualisations.\nimport plotly.io as pio\nimport plotly.express as px\n\n# Set renderer\npio.renderers.default='browser'\n\n# Create bar plot\npx.bar(df, x = \"Name\", y = \"Age\")",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#saving-your-work",
    "href": "WIPs/1 - Fundamentals.html#saving-your-work",
    "title": "The Fundamentals",
    "section": "Saving your work",
    "text": "Saving your work\nPress “Save” or Ctrl + S to save your script.\nYour project can be reopened from the “Projects” menu in Spyder.\nBy default, your variables are not saved, which is another reason why working with a script is important: you can execute the whole script in one go to get everything back. You can however save your variables as a .spydata file if you want to (for example, if it takes a lot of time to process your data).",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "WIPs/1 - Fundamentals.html#summary",
    "href": "WIPs/1 - Fundamentals.html#summary",
    "title": "The Fundamentals",
    "section": "Summary",
    "text": "Summary\nThis morning we looked at a lot of Python features, so don’t worry if they haven’t all sunk in. Programming is best learned through practice, so keep at it! Here’s a rundown of the concepts we covered\n\n\n\n\n\n\n\nConcept\nDesctiption\n\n\n\n\nThe console vs scripts\nThe console is our window into the computer, this is where we send code directly to the computer. Scripts are files which we can write, edit, store and run code, that’s where you’ll write most of your Python.\n\n\nVariables\nVariables are the nouns of programming, this is where we store information, the objects and things of our coding. They come in different types like integers, strings and lists.\n\n\nIndexing\nIn order to access elements of a sequence variable, like a list, we need to index, e.g. example_numbers[2]. Python counts from 0.\n\n\nFunctions\nFunctions are the verbs of programming, they perform actions on our variables. Call the function by name and put inputs inside parentheses, e.g. round(2.5)\n\n\nHelp\nRunning help( ... ) will reveal the help documentation about a function or type.\n\n\nPackages\nWe can bring external code into our environment with import .... This is how we use packages, an essential for Python. Don’t forget to install the package first!",
    "crumbs": [
      "WIPs",
      "The Fundamentals"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Python Training Intensive",
    "section": "",
    "text": "Welcome to the Python Training Intensive!",
    "crumbs": [
      "Python Training Intensive"
    ]
  },
  {
    "objectID": "setup.html#setting-up",
    "href": "setup.html#setting-up",
    "title": "Python Training Intensive",
    "section": "Setting Up",
    "text": "Setting Up\nWe are going to use Spyder for writing and running Python. This is a friendly interactive development environment (IDE) aimed at researchers. However, you are more than welcome to use your own!\nPlease set up Python and your IDE in advance.\nIf you don’t have Python or an IDE, we recommend installing Spyder, which comes with Python.",
    "crumbs": [
      "Python Training Intensive"
    ]
  },
  {
    "objectID": "Workshops/Workshops.html",
    "href": "Workshops/Workshops.html",
    "title": "Workshops landing page",
    "section": "",
    "text": "Workshops landing page",
    "crumbs": [
      "Workshops",
      "Workshops landing page"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html",
    "href": "WIPs/2 - Data processing.html",
    "title": "Data Processing",
    "section": "",
    "text": "In this second workshop we will cover\nThis hands-on course – directed at intermediate users – looks at using the pandas module to transform and visualise tabular data.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#setting-up",
    "href": "WIPs/2 - Data processing.html#setting-up",
    "title": "Data Processing",
    "section": "Setting up",
    "text": "Setting up\n\nIntroducing pandas\nPandas is a Python module that introduces dataframes to Python. It gives us the tools we need to clean and transform data with Python.\nTo be able to use the functions included in pandas, we have to first import it:\nimport pandas as pd\npd is the usual nickname for the pandas module.\n\nIf you get an error, like No module named 'pandas', you’ll need to install it first, using either conda install pandas or pip install pandas, depending on your Python installation.\n\n\nThe DataFrame object\nPandas is built upon one key feature: the DataFrame class. In Python we have different built-in types, like int for integers and string for characters. Pandas introduces a new type, DataFrame, which stores data like a spreadsheet.\n\n\n\nSetting up the workspace\nTo make life easy, we should set up our workspace well.\n\nOpen your project folder using your file explorer, and create a new folder called “data”.\nMove your data into this folder.\nNext, open your project in Spyder, and create a new script called “analysis.py”.\nOpen the “Files” tab in Spyder and check that you see two objects:\n\nThe file “analysis.py”\nThe folder “data”\n\n\n\n\nImporting data\nPandas offers a simple way to access data with its read.csv() function. We’ll save it into the variable df_raw:\ndf_raw = pd.read_csv(\"data/name_of_file_here.csv\")\n\nYou can also provide a URL instead of a file path!\n\n\n\nAside - File Paths and backslashes\nJust a quick detour to discuss file paths of which there are two types: absolute and relative\n\nAbsolute\nAbsolute file paths always start at the “top” of your file system, e.g. one of the drives (like C:) for Windows users, so they are never ambiguous. It’s like providing your full address from country to street number.\nC://Users/my_username/research/data/really_important_secret_data.csv\n\n\nRelative\nRelative file paths start from your current file location. For files in my current folder, I just provide their name - like referring to another house on your street as “number 7”. Let’s assume we’re in the research folder.\nfile_in_my_current_folder.csv\nWe can go to down folders from our current location:\ndata/really_important_secret_data.csv\nAnd we can go up folders from our current location\n../../this_file_is_two_levels_up.csv\nOr a combination of the two (e.g. up one, then down into a different folder)\n../not_research/this_file_is_not_research.csv\nWhat matters is that the relative reference depends on where your code is and will break if you move the script!\n\n\nBackslashes\nOne last note: Windows uses backslashes for their file paths\nC:\\\\Users\\...\nBut Python uses backslashes as an escape character. For example, \"\\n\" is a newline, \"\\u1234\" is the unicode character U+1234 and confusingly \"\\\\\" is a single backslash. So we have to modify all Windows file paths to either\nC:\\\\\\\\Users\\\\...\n\nOR\n\nC://Users/...\nYou can choose whichever you prefer.\n\n\n\nInitial look at the data\nLet’s get back to data.\nWe can investigate the size of the data thanks to the shape attribute attached to all pandas dataframes:\ndf_raw.shape\nThe dataset contains dozens of columns. What are their names?\ndf_raw.columns\nLet’s subset our data to focus on a handful of variables.\n\n\nCreating a backup\nData analysis in Python is safe because our variables are copies of the data - we aren’t actually changing the files until we explicitly overwrite them. However, Python also has no undo, so if I delete something in my analysis, I can’t get it back - I have to start all over again.\nOne way to mitigate this issue is by making a copy of the data\ndf = df_raw.copy()\nNow we have two variables: df is what we’ll use, and df_raw stores the raw data. If we ever need to restart, we can simply run df = df_raw.copy().",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#accessing-and-filtering-data",
    "href": "WIPs/2 - Data processing.html#accessing-and-filtering-data",
    "title": "Data Processing",
    "section": "Accessing and Filtering Data",
    "text": "Accessing and Filtering Data\nSo how do we access our data in Python? We use a type of indexing introduced by pandas, which revolves around using square brackets after the dataframe: df[...].\n\nAccessing columns\nTo access a column, index with its name:\ndf[\"column_name\"]\nWe can access multiple by providing a list of names\n# Save the names in a list and then index\ncolumn_names = [\"name_1\", \"name_2\"]\ndf[column_names]\n\n# This is equivalent to\ndf[[\"name_1\", \"name_2\"]]\nIf we want to do anything with it (like statistics or visualisation), it’s worth saving the column(s) as a new variable\ndf_subset = df[[\"name_1\", \"name_2\"]]\n\n\nAccessing rows\nThere’s a few ways to access rows. The easiest is by slicing - if you want rows 5 to 10, use df[5 : 10]\n\nNote that the end row is not included\n\ndf[start_row : end_row]\nIf you want to access a single row, we need to use df.loc[] or df.iloc[]. These are the go-to methods for accessing data if the above indexing isn’t sufficient.\n\ndf.loc[] accesses rows by label (defaults to row number but could be anything)\ndf.iloc[] accesses rows by row number exclusively\n\nFor a single row\ndf.loc[row_label]\ndf.iloc[row_num]\nFinally, we can filter specific rows by a condition on one of the variables, e.g. only rows where variable \\(x &gt; 15\\).\ndf[df[\"column_x\"] &gt; 15]\n# Or any other condition\nAs with the column case, it’s useful to save this as a variable\ndf_filtered = df[df[\"column_x\"] &gt; 15]",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#basic-statistics",
    "href": "WIPs/2 - Data processing.html#basic-statistics",
    "title": "Data Processing",
    "section": "Basic statistics",
    "text": "Basic statistics\nHow might we perform some basic statistics on our data?\nTo check what kind of data each column is stored as, we can use the dtypes attribute:\ndf.dtypes\n\nIn general, pandas will bring in numbers with float64 and non-numeric data with object.\n\nThe describe() method is useful for descriptive statistics about our numerical columns:\ndf.describe()\nHowever, it will only show the two first ones and two last ones. We can focus on a specific column instead, for example one that was hidden previously:\ndf[\"column\"].describe()\nOr a categorical column:\ndf[\"categorical_column\"].describe()\n\nFor a categorical column, the information shown is different: for example, how many unique values there are, and what the most common value is.\n\nWhat if you want specific statistics about a particular column? Usually there are methods available:\n# Applicable to all columns\ndf[\"column\"].count()\ndf[\"column\"].unique()\n\n# For numeric columns only\ndf[\"numeric_column\"].min()\ndf[\"numeric_column\"].max()\ndf[\"numeric_column\"].mean()\ndf[\"numeric_column\"].median()\ndf[\"numeric_column\"].std()\n# ...\nWe can use these methods to filter our data. For example, the row which has the maximum value of variable \\(x\\) is\nx_max = df[\"variable_x\"].max()\ndf[df[\"variable_x\"] == x_max]\n\n# Or in one line\ndf[df[\"variable_x\"] == df[\"variable_x\"].max()]\nbecause we are looking for the row in df[\"variable_x\"] (the whole column) that has the value df[\"variable_x\"].max().",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#challenge",
    "href": "WIPs/2 - Data processing.html#challenge",
    "title": "Data Processing",
    "section": "Challenge",
    "text": "Challenge\nReduce your dataset to \\(\\le 5\\) variables (columns) and \\(\\le 100\\) rows using conditions by filtering down to a particular subset of your data.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#adding-and-removing-columns",
    "href": "WIPs/2 - Data processing.html#adding-and-removing-columns",
    "title": "Data Processing",
    "section": "Adding and removing columns",
    "text": "Adding and removing columns\nSometimes we need to add new columns. It’s the same process as overwriting existing columns - let’s make a new column called “zeroes” where every row is 0\ndf[\"zeroes\"] = 0\nWe can also send in a column, for example\ndf[\"copy_of_x\"] = df[\"column_x\"]\nPerhaps most usefully, we can manipulate the column we send in. For example, the deviation from the mean \\[|\\bar{x} - x_i|\\] can be computed for each row:\ncol_x = df[\"column_x\"]\navg_x = df[\"column_x\"].mean()\n\ndf[\"deviation_from_mean\"] = abs(col_x - avg_x)\n\n# Or all together on one line,\ndf[\"deviation_from_mean\"] = abs(df[\"column_x\"] - df[\"column_x\"].mean())\nwhere abs(...) takes the absolute value\nNotice that we subtracted a value from a column. We can also perform mathematics with multiple columns:\ndf[\"product\"] = df[\"column_x\"]*df[\"column_y\"]\nLet’s remove these new columns that we don’t need with the method df.drop(columns = [...]):\ndf.drop(columns = [\"zeroes\", \"copy_of_x\", \"deviation_from_mean\", \"product\"])",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#summaries",
    "href": "WIPs/2 - Data processing.html#summaries",
    "title": "Data Processing",
    "section": "Summaries",
    "text": "Summaries\nAfter cleaning up our data, we need to analyse it. This usually involves some kind of aggregation. For example, what is the average \\(x\\) per year? requires aggregating over variable \\(x\\) for each year.\nFirst, we need to group by a specific variable\ngb = df.groupby(\"year\")\nThis thing in itself is a pretty abstract Python object, best thought of as a dataframe where we’ve identified a grouping variable.\nNext, we need to apply some aggregation to it (the groupby tells it to do it for each year)\navg_x_per_year = gb[\"variable_x\"].agg(\"mean\")\nOf course, we could have done this in one line:\navg_x_per_year = df.groupby(\"year\").agg(\"mean\")\nThis is a really useful tool, because now we have something we can visualise. As the next session will show us, the visualisation tools generally just take in numbers and turn them into dots. We need to do the stats beforehand.\nAs a taster, try running\navg_x_per_year.plot()",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#exporting-results",
    "href": "WIPs/2 - Data processing.html#exporting-results",
    "title": "Data Processing",
    "section": "Exporting results",
    "text": "Exporting results\nThe last step in the process is saving the data. Let’s say we want to take that final dataframe and export it to a csv. That’s what the df.to_csv() method is for\navg_x_per_year.to_csv(\"data/avg_x_per_year.csv\")\nThis will save the dataframe to a .csv file and place it in the data folder.",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/2 - Data processing.html#resources",
    "href": "WIPs/2 - Data processing.html#resources",
    "title": "Data Processing",
    "section": "Resources",
    "text": "Resources\n\nOfficial pandas documentation\n\nGetting started\n10 Minutes to pandas\nUser guide\n\nMore visualisation modules:\n\nAltair\nBokeh\nVega\nMatplotlib\n\nOur compilation of useful Python links",
    "crumbs": [
      "WIPs",
      "Data Processing"
    ]
  },
  {
    "objectID": "WIPs/4 - Sharing and Publishing.html",
    "href": "WIPs/4 - Sharing and Publishing.html",
    "title": "Version Control",
    "section": "",
    "text": "In this workshop we cover using GitHub for version control, looking specifically at\n\nHow to use create a repo and commit to it\nHow to push and pull from the command line\nHow to integrate with VS code\nHow to clone and fork other repositories",
    "crumbs": [
      "WIPs",
      "Version Control"
    ]
  },
  {
    "objectID": "WIPs/6 - Programming.html",
    "href": "WIPs/6 - Programming.html",
    "title": "Programming Building Blocks",
    "section": "",
    "text": "In this workshop we cover the building blocks for developing more complex code, looking at",
    "crumbs": [
      "WIPs",
      "Programming Building Blocks"
    ]
  },
  {
    "objectID": "WIPs/6 - Programming.html#directing-traffic-with-conditionals",
    "href": "WIPs/6 - Programming.html#directing-traffic-with-conditionals",
    "title": "Programming Building Blocks",
    "section": "Directing traffic with conditionals",
    "text": "Directing traffic with conditionals\nIn the first half of this session we’ll look at two types of control flows: conditionals and loops.\nConditionals allow you to put “gates” in your code, only running sections if a certain condition is true. They are common to most programming languages.\nIn Python, they are called if statements, because you use the if command. For example,\nif 5 &gt; 0:\n    print(\"We're inside the if statement\")\nThe line print(\"We're inside the if statement\") will only run if 5 &gt; 0 is true. If not, it’ll get skipped.\nIndents are essential. Only indented code will be governed by conditional\nif 5 &gt; 0:\n    print(\"We're inside the if statement\")\n\nprint(\"This code always runs\")\nWatch what happens if we change the condition\nif 5 &gt; 10:\n    print(\"We're inside the if statement\")\n\nprint(\"This code always runs\")\nNow, the first line doesn’t run. That’s the essence of a conditional.\nThere’s not much point to using a condition that will always be true. Typically, you’d use a variable in the condition, for example.\npet_age = 10\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\n\nLogical operators\nHere is a table of the different operators you can make conditions with. When you run them, they always return either True or False.\n\n\n\n\n\n\n\n\nOperator\nTrue example\nDescription\n\n\n\n\n==\n10 == 10\nSame value and type\n\n\n!=\n\"10\" != 10\nDifferent value or type\n\n\n&gt;\n10 &gt; 5\nGreater than\n\n\n&gt;=\n10 &gt;= 10\nGreater than or equal to\n\n\n&lt;\n5 &lt; 10\nLess than\n\n\n&lt;=\n5 &lt;= 10\nLess than or equal to\n\n\nin\n\"a\" in \"apple\"\nFirst object exists in the second\n\n\nnot in\n\"b\" not in \"apple\"\nFirst object does not exist in the second\n\n\nand\n10 == 10 and \"a\" in \"apple\"\nOnly true if both conditions are true. Same as &\n\n\nor\n10 == 10 or \"b\" in \"apple\"\nAlways true if one condition is true. Same as \\|\n\n\n\n\n\nelif and else\nif statements only run if the condition is True. What happens if its False? That’s what the else command is for, it’s like a net that catches anything that slipped past if:\npet_age = 5\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\nelse:\n    print(\"My pet is 10 or younger\")\n\nDon’t forget the colon :!\n\nCheck what happens when you change the age from 5 to 15.\nFinally, what if you wanted to check another condition only if the first one fails? That’s what elif (else-if) is for. It’s another if statement but it only runs if the first fails.\npet_age = 5\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\nelif pet_age &lt; 5:\n    print(\"My pet is younger than 5\")\nelse:\n    print(\"My pet is between 5 and 10\")\nYou can include as many as you’d like\npet_age = 5\n\nif pet_age &gt; 10:\n    print(\"My pet is older than 10\")\nelif pet_age &lt; 5:\n    print(\"My pet is younger than 5\")\nelif pet_age &lt; 1:\n    print(\"My pet is freshly born\")\nelse:\n    print(\"My pet is between 5 and 10\")",
    "crumbs": [
      "WIPs",
      "Programming Building Blocks"
    ]
  },
  {
    "objectID": "WIPs/6 - Programming.html#repeat-after-me",
    "href": "WIPs/6 - Programming.html#repeat-after-me",
    "title": "Programming Building Blocks",
    "section": "Repeat after me",
    "text": "Repeat after me\nSometimes you need to repeat a task multiple times. Sometimes hundreds. Maybe you need to loop through 1 million pieces of data. Not fun.\nPython’s loops offer us a way to run a section of code multiple times. There are two types: for loops, which run the code once for each element in a sequence (like a list or string), and while loops, which run until some condition is false.\n\nwhile loops\nThese are almost the same as if statements, except for the fact that they run the code multiple times. Let’s begin with a basic conditional\nnumber = 5\n\nif number &lt; 10:\n    print(number + \"is less than 10.\")\nThe print statement runs once if the condition is true.\nWhat if we wanted to check all the numbers between 5 and 10? We can use a while loop.\nnumber = 5\n\nwhile number &lt; 10:\n    print(number + \"is less than 10.\")\n    number = number + 1\nWe’ve done two things\n\nReplace if with while\nIntroduce number = number + 1 to increase the number each time.\n\n\nWithout step 2, we’d have an infinite loop – one that never stops, because the condition would always be true!\n\nWhile loops are useful for repeating code an indeterminate number of times.\n\n\nfor loops\nRealistically, you’re most likely to use a for loop. They’re inherently safer (you can’t have an infinite loop) and often handier.\nIn Python, for loops iterate through a sequence, like the objects in a list. This is more like other languages’ foreach, than most’s for.\nLet’s say you have a list of different fruit\nlist_of_fruits = [\"apple\", \"banana\", \"cherry\"]\nand you want to run a section of code on \"apple\", then \"banana\", then \"cherry\". Maybe you want to know which ones have the letter “a”. We can start with a for loop\nlist_of_fruits = [\"apple\", \"banana\", \"cherry\"]\n\nfor fruit in list_of_fruits:\n    print(fruit)\nThis loop’s job is to print out the variable fruit. But where is fruit defined? Well, the for loop runs print(fruit) for every element of list_of_fruits, storing the current element in the variable fruit. If we were to write it out explicitly, it would look like\nfruit = list_of_fruits[0]\nprint(fruit)\n\nfruit = list_of_fruits[1]\nprint(fruit)\n\nfruit = list_of_fruits[2]\nprint(fruit)\nLet’s return to our goal: working out which ones have an “a”. We need to put a conditional inside the loop:\nlist_of_fruits = [\"apple\", \"banana\", \"cherry\"]\n\nfor fruit in list_of_fruits:\n    if \"a\" in fruit:\n        print(\"a is in \" + fruit)\n    else:\n        print(\"a is not in \" + fruit)\n\n\nUsing range\nThere’s a special Python object which is useful for loops, the range. This object ‘contains’ all the numbers between a certain range. For example,\nrange(0,5)\ncover the numbers \\(0-4\\), and is somewhat equivalent to [0,1,2,3,4] (for looping purposes). Of course, we can choose a much bigger number:\nfor i in range(0,1000)\n    print(i)\nwill print every number between \\(0\\) and \\(1000\\). This can be useful if you need to loop through multiple objects by indexing.",
    "crumbs": [
      "WIPs",
      "Programming Building Blocks"
    ]
  },
  {
    "objectID": "WIPs/6 - Programming.html#looking-under-the-hood-what-makes-ints-ints",
    "href": "WIPs/6 - Programming.html#looking-under-the-hood-what-makes-ints-ints",
    "title": "Programming Building Blocks",
    "section": "Looking under the hood: what makes ints ints?",
    "text": "Looking under the hood: what makes ints ints?\nPython is a high level programming language. Its features are often inspired by C and C++, and is itself built in C/C++.\nOne of the major innovations of C++, and object-oriented programming in general, are classes. We won’t go over how to write your own - it’s beyond the scope of this workshop - but they’re worth a conceptual understanding.\nEssentially, all Python variables follow a specific template, known as its class or type. It’s safe to use these interchangebly here. The class is a general template for the variable and it defines what methods (functions) and attributes (variables) live inside the variable.\nInside the variable? Where? Well, a variables contain more than just their value. We use the . operator to access anything besides the value that lives in the variable. For example, all strings have a function called .upper() that makes them uppercase:\nrandom_string = \"Hello, this is a sentence.\"\nprint(random_string.upper())\nLet me emphasise that all strings have .upper(). That makes upper() a method of strings.\nIn other words, a class is like an empty form that needs filling. The form string has a field called upper() that is filled with the function as defined above.",
    "crumbs": [
      "WIPs",
      "Programming Building Blocks"
    ]
  },
  {
    "objectID": "WIPs/6 - Programming.html#building-your-own-machines",
    "href": "WIPs/6 - Programming.html#building-your-own-machines",
    "title": "Programming Building Blocks",
    "section": "Building your own machines",
    "text": "Building your own machines\nWe’ll wrap this session up by looking at custom functions and modules. So far, we’ve only used built-in functions or those from other people’s modules. But we can make our own!\nWe’ve only ever called functions - this is what we do when we use them. All functions need a definition, this is the code that gets run when they’re called.\n\nThe function definition\nFunctions are machines. They take some inputs, run some code with those inputs, and spit out one output. We need to define how they work before we use them. We should specify\n\nA name\nSome inputs\nThe code to run (the machine itself)\nAn output\n\nWe include these in three steps\n\nThe first line of the function definition (the function signature) specifies the name and inputs\nWe then indent all the code we want to run with our inputs\nWe end with a return statement, specifying the output\n\ndef insert_function_name_here(input_1_name, input_2_name, ...):\n    # Code code code\n    return output\nFor example, let’s create a function that converts centimetres to metres.\ndef cm_to_m(value_in_cm):\n    value_in_m = value_in_cm / 100\n    return value_in_m\nTaking it apart, we have\n\nName: cm_to_m\nInputs (just one): value_in_cm\nCode (just one line): value_in_m = value_in_cm / 100\nOutput: value_in_m\n\nImportantly, nothing happens when you run this code. Why? Because you’ve only defined the function, you haven’t used it yet.\nTo use this function, we need to call it. Let’s convert \\(10\\text{ cm}\\) to \\(\\text{m}\\).\ndef cm_to_m(value_in_cm):\n    value_in_m = value_in_cm / 100\n    return value_in_m\n\ncm_to_m(10)\nWhen we call the function, it runs with value_in_cm = 10.\nThat’s it! Every function that you use, built-in or imported, looks like this.\nBecause functions must be defined before called, and defining them produces no output, best practice is to place functions at the top of your script, below the import statements.\n\n\nDocstrings\nSomething you’ll spot on all professional functions are docstrings. This is what Python spits out with the help() function. You can make your own by writing it within triple quotes immediately after the signature ''' ''':\ndef cm_to_m(value_in_cm):\n    \"\"\"Converts centimetres to metres\"\"\"\n    value_in_m = value_in_cm / 100\n    return value_in_m\n\ncm_to_m(10)\nThat said, the best way to ensure clarity is to use a clear name.\n\n\nCreating modules\nWhat if you need to write lots of functions? We could write unit converters like above for hundreds of possibilities.\nIt’s useful to tuck these away in their own file, so they don’t clog up your main.py.\nLet’s make a new file called conversions.py, and move your function into it. Delete it from your current file.\nThen, to make sure it works, let’s make a new converter too, from centimetres to inches. Your conversions.py file should look like:\ndef cm_to_m(value_in_cm):\n    \"\"\"Converts centimetres to metres\"\"\"\n    value_in_m = value_in_cm / 100\n    return value_in_m\n\ndef cm_to_in(value_in_cm):\n    \"\"\"Converts centimetres to inches\"\"\"\n    value_in_inches = value_in_cm / 2.54\n    return value_in_inches\nLet’s make another script now called main.py. We’ll run our conversions here by pulling in the functions from conversions.py.\nInside main.py, you’ll need to import conversions.py. To access the functions, you’ll need to use . to look inside the module as usual:\nimport conversions\nmetres = conversions.cm_to_m(10)\ninches = conversions.cm_to_in(10)\n\nprint(\"10cm is \" + metres + \"m\")\nprint(\"10cm is \" + inches + \"\\\"\")\n\nTo include a double quote ” inside a string made of double quotes, escape it with a backslash: \\\".\n\nCongratulations, you’ve made your first module!",
    "crumbs": [
      "WIPs",
      "Programming Building Blocks"
    ]
  }
]